{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564b4df2",
   "metadata": {},
   "source": [
    "## Corpus & Normalization: Understanding Text Data\n",
    "A corpus is a large collection of text used in NLP (Natural Language Processing). Understanding word distributions, vocabulary size, and normalization techniques is crucial for text analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6853bedb",
   "metadata": {},
   "source": [
    "### **1. Word Types & Vocabulary Size (`|V|`)**\n",
    "**Word Types** refer to unique words in a text, while **Vocabulary Size** is the count of these unique words.\n",
    "- **Example:** In \"hello world hello\", the word types are `{hello, world}`, so `|V| = 2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ac0ac",
   "metadata": {},
   "source": [
    "### **2. Word Instances (`N`)**\n",
    "**Word Instances** count all words, including repetitions.\n",
    "- **Example:** In \"hello world hello\", the total word instances `N = 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d6fa07",
   "metadata": {},
   "source": [
    "### **3. Herdanâ€™s Law**\n",
    "- **Concept:** The number of unique words (word types) increases slowly compared to the total word instances.\n",
    "- **Example:** A book may have 100,000 words, but only 20,000 unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ffb0c",
   "metadata": {},
   "source": [
    "### **4. Heapâ€™s Law (`|V| = kN^Î²`)**\n",
    "- **Formula:** Vocabulary size grows in proportion to total words following this law.\n",
    "- **Example:** If `k=10` and `Î²=0.5`, then for `N=10000`, the vocabulary size is `|V| = 10 * (10000)^0.5 = 1000`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c2e0e",
   "metadata": {},
   "source": [
    "### **5. Lemma & Text Normalization**\n",
    "- **Lemma** is the base or dictionary form of a word (used in text normalization).\n",
    "- **Example:** *run, runs, running* â†’ **run** (lemma)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a756618",
   "metadata": {},
   "source": [
    "### **6. Word Forms**\n",
    "- **Different forms of a word based on tense or grammar.**\n",
    "- **Example:** *eat, ate, eaten* (different forms of \"eat\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b9c73",
   "metadata": {},
   "source": [
    "### **7. Code Switching**\n",
    "Mixing languages within a sentence.\n",
    "- **Example:** \"Naan enna solrenaa, I am a good boy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96396b76",
   "metadata": {},
   "source": [
    "### **8. Data Sheet / Data Statement**\n",
    "- **Motivation:** Why was the corpus collected, by whom, and who funded it?\n",
    "- **Situation:** When and where was the text written/spoken? Was it a conversation, edited text, or social media communication?\n",
    "- **Language Variety:** What language (dialect/region) is the corpus in?\n",
    "- **Speaker Demographics:** Age, gender, and background of the text authors.\n",
    "- **Collection Process:** How was the data collected? Was consent obtained? How was it pre-processed?\n",
    "- **Annotation Process:** What annotations exist? Who annotated it? How were they trained?\n",
    "- **Distribution:** Are there copyright or intellectual property restrictions?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72059673",
   "metadata": {},
   "source": [
    "## Useful UNIX Commands for Text Processing\n",
    "**Instructions:** Ensure your corpus file is named `sh.txt` and located in the same directory where you run these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e831000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words and list them line by line\n",
    "!tr -sc 'A-Za-z' '\\n' < sh.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to uppercase\n",
    "!tr -sc A-Za-z '\\t' < sh.txt | tr a-z A-Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words and their frequency\n",
    "!tr -sc 'A-Za-z' '\\n' < 'sh.txt' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lowercase and sort by frequency\n",
    "!tr -sc 'A-Za-z' '\\n' < sh.txt | tr A-Z a-z | sort | uniq -c | sort -n -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc3777",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "Understanding corpus statistics, text normalization, and UNIX commands for text processing is essential for NLP. These concepts help in language modeling, text mining, and AI applications. Which concept do you find most interesting? Letâ€™s discuss! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
